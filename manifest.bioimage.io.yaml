format_version: 0.2.0
config:
  id: zero
  name: ZeroCostDL4Mic
  version: 1.7.1
  tags:
    - ZeroCostDL4Mic
  logo: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostLogo.png
  icon: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostLogo.png
  splash_title: ZeroCostDL4Mic
  splash_subtitle: A Google Colab based no-cost toolbox to explore Deep-Learning in Microscopy
  splash_feature_list: []
  explore_button_text: Start Exploring
  background_image: static/img/zoo-background.svg
  resource_types:
    - model
    - application
    - dataset
  default_type: application
  url_root: https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master

dataset:
  # see here for the format: https://bioimage.io/#/?show=contribute
  # replace this with your actual dataset
  - id: Dataset_StarDist_2D_ZeroCostDL4Mic_2D
    name: StarDist (2D) example training and test dataset - ZeroCostDL4Mic
    description: Fluorescence microscopy (SiR-DNA) and masks obtained via manual segmentation
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors: [Johanna Jukkala, Guillaume Jacquemet]
    documentation: >-
      https://doi.org/10.5281/zenodo.3715492
    tags: [StarDist, segmentation, ZeroCostDL4Mic, 2D]
    source: https://doi.org/10.5281/zenodo.3715492
    covers:
      - https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/Stardist_nuclei_masks.png

  - id: Dataset_Noise2Void_2D_ZeroCostDL4Mic
    name: Noise2Void (2D) example training and test dataset - ZeroCostDL4Mic
    description: Fluorescence microscopy (paxillin-GFP)
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors: [Aki Stubb, Guillaume Jacquemet, Johanna Ivaska]
    documentation: >-
      https://doi.org/10.5281/zenodo.3713315
    tags: [Noise2Void, denoising, ZeroCostDL4Mic, 2D]
    source: https://doi.org/10.5281/zenodo.3713315
    covers:
      - https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/N2V_wiki.png

  - id: Dataset_Noise2Void_3D_ZeroCostDL4Mic
    name: Noise2Void (3D) example training and test dataset - ZeroCostDL4Mic
    description: Fluorescence microscopy (Lifeact-RFP)
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors: [Guillaume Jacqueme]
    documentation: >-
      https://doi.org/10.5281/zenodo.3713326
    tags: [Noise2Void, denoising, ZeroCostDL4Mic, 3D]
    source: https://doi.org/10.5281/zenodo.3713326
    covers:
      - https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/TrainingDataset_ShowOff_v3.png

  - id: Dataset_CARE_2D_ZeroCostDL4Mic
    name: CARE (2D) example training and test dataset - ZeroCostDL4Mic
    description: Fluorescence microscopy (Lifeact-RFP)
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors: [Guillaume Jacqueme]
    documentation: >-
      https://doi.org/10.5281/zenodo.3713330
    tags: [CARE, denoising, ZeroCostDL4Mic, 2D]
    source: https://doi.org/10.5281/zenodo.3713330
    covers:
      - https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/CARE_wiki.png

  - id: Dataset_CARE_3D_ZeroCostDL4Mic
    name: CARE (3D) example training and test dataset - ZeroCostDL4Mic
    description: Fluorescence microscopy (Lifeact-RFP)
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors: [Guillaume Jacqueme]
    documentation: >-
      https://doi.org/10.5281/zenodo.3713337
    tags: [CARE, denoising, ZeroCostDL4Mic, 3D]
    source: https://doi.org/10.5281/zenodo.3713337
    covers:
      - https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/CARE_wiki.png

  - id: Dataset_fnet_3D_ZeroCostDL4Mic
    name: Label-free prediction (fnet) example training and test dataset - ZeroCostDL4Mic
    description: Confocal microscopy data (TOM20 labeled with Alexa Fluor 594)
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors: [Christoph Spahn]
    documentation: >-
      https://doi.org/10.5281/zenodo.3748967
    tags: [fnet, labelling, ZeroCostDL4Mic, 3D]
    source: https://doi.org/10.5281/zenodo.3748967
    covers:
      - https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/Fnet_exemplary_data_mitochondria.png

  - id: Dataset_Deep-STORM_ZeroCostDL4Mic
    name: Deep-STORM training and example dataset - ZeroCostDL4Mic
    description: Time-series of simulated, randomly distributed single-molecule localization (SMLM) data (Training dataset). Experimental time-series dSTORM acquisition of Glial cells stained with phalloidin for actin (Example dataset).
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors: [Christophe Leterrier, Romain F. Laine]
    documentation: >-
      https://doi.org/10.5281/zenodo.3959089
    tags: [SMLM, Deep-STORM, ZeroCostDL4Mic, 2D]
    source: https://doi.org/10.5281/zenodo.3959089

    covers:
      - https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/TrainingDataset_ShowOff_v3.png

  - id: Dataset_CycleGAN_ZeroCostDL4Mic
    name: CycleGAN example training and test dataset - ZeroCostDL4Mic
    description: Unpaired microscopy images (fluorescence) of microtubules (Spinning-disk and SRRF reconstructed images)
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors: [Guillaume Jacquemet]
    documentation: >-
      https://doi.org/10.5281/zenodo.3941884
    tags: [CycleGAN, ZeroCostDL4Mic]
    source: https://doi.org/10.5281/zenodo.3941884

    covers:
      - https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/unpaired-image_translation.png

  - id: Dataset_pix2pix_ZeroCostDL4Mic
    name: pix2pix example training and test dataset - ZeroCostDL4Mic
    description: Paired microscopy images (fluorescence) of lifeact-RFP and sir-DNA
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors: [Guillaume Jacquemet]
    documentation: >-
      https://doi.org/10.5281/zenodo.3941889
    tags: [pix2pix, ZeroCostDL4Mic]
    source: https://doi.org/10.5281/zenodo.3941889

    covers:
      - https://github.com/HenriquesLab/ZeroCostDL4Mic/raw/master/Wiki_files/paired-image_translation.png

  - id: Dataset_YOLOv2_ZeroCostDL4Mic
    name: YoloV2 example training and test dataset - ZeroCostDL4Mic
    description: 2D grayscale .png images with corresponding bounding box annotations in .xml  PASCAL Voc format.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors: [Guillaume Jacquemet, Lucas von Chamier]
    documentation: >-
      https://doi.org/10.5281/zenodo.3941908
    tags: [YOLOv2, ZeroCostDL4Mic]
    source: https://doi.org/10.5281/zenodo.3941908

    covers:
      - https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/TrainingDataset_ShowOff_v3.png


  - id: Dataset_StarDist_Fluo_ZeroCostDL4Mic
    name: Combining StarDist and TrackMate example 1 - Breast cancer cell dataset
    description: Fluorescence microscopy of Nuclei (SiR-DNA) and masks obtained via manual segmentation
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    cite:
      text: "Elnaz Fazeli, Nathan H. Roy, Gautier Follain, Romain F. Laine, Lucas von Chamier, Pekka E. Hänninen, John E. Eriksson, Jean-Yves Tinevez, Guillaume Jacquemet. Automated cell tracking using StarDist and TrackMate. bioRxiv, 2020. DOI: https://doi.org/10.1101/2020.09.22.306233"
      doi: https://doi.org/10.1101/2020.09.22.306233

    authors: [Guillaume Jacquemet]
    documentation: >-
      https://doi.org/10.5281/zenodo.3941884
    tags: [StarDist, ZeroCostDL4Mic]
    source: https://zenodo.org/record/4034976
    download_url: https://zenodo.org/record/4034976

    covers:
      - https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingfluo_trackmate.png


  - id: Dataset_StarDist_brightfield_ZeroCostDL4Mic
    name: Combining StarDist and TrackMate example 2 - T cell dataset
    description: Paired brightfield images of migrating T cells and corresponding masks
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    cite:
      text: "Elnaz Fazeli, Nathan H. Roy, Gautier Follain, Romain F. Laine, Lucas von Chamier, Pekka E. Hänninen, John E. Eriksson, Jean-Yves Tinevez, Guillaume Jacquemet. Automated cell tracking using StarDist and TrackMate. bioRxiv, 2020. DOI: https://doi.org/10.1101/2020.09.22.306233"
      doi: https://doi.org/10.1101/2020.09.22.306233

    authors: [Nathan H. Roy, Guillaume Jacquemet]
    documentation: >-
      https://doi.org/10.5281/zenodo.3941884
    tags: [StarDist, ZeroCostDL4Mic]
    source: https://zenodo.org/record/4034929
    download_url: https://zenodo.org/record/4034929

    covers:
      - https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingTcells_trackmate.png

  - id: Dataset_StarDist_brightfield2_ZeroCostDL4Mic
    name: Combining StarDist and TrackMate example 3 - Flow chamber dataset
    description: Paired brightfield images of cancer cells and corresponding masks
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    cite:
      text: "Elnaz Fazeli, Nathan H. Roy, Gautier Follain, Romain F. Laine, Lucas von Chamier, Pekka E. Hänninen, John E. Eriksson, Jean-Yves Tinevez, Guillaume Jacquemet. Automated cell tracking using StarDist and TrackMate. bioRxiv, 2020. DOI: https://doi.org/10.1101/2020.09.22.306233"
      doi: https://doi.org/10.1101/2020.09.22.306233

    authors: [Gautier Follain, Guillaume Jacquemet]
    documentation: >-
      https://doi.org/10.5281/zenodo.3941884
    tags: [StarDist, ZeroCostDL4Mic]
    source: https://zenodo.org/record/4034939
    download_url: https://zenodo.org/record/4034939

    covers:
      - https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/StarDist_trainingflo_trackmate.png


application:
  - id: Notebook Preview
    source: https://raw.githubusercontent.com/bioimage-io/nbpreview/master/notebook-preview.imjoy.html

  - id: Notebook_U-Net_2D_ZeroCostDL4Mic
    name: U-Net (2D) - ZeroCostDL4Mic
    description: U-Net is an encoder-decoder architecture originally used for image segmentation. The first half of the U-Net architecture is a downsampling convolutional neural network which acts as a feature extractor from input images. The other half upsamples these results and restores an image by combining results from downsampling with the upsampled images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Romain Laine and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, U-Net, segmentation, ZeroCostDL4Mic, 2D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/U-Net_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview

  - id: Notebook_U-Net_3D_ZeroCostDL4Mic
    name: U-Net (3D) - ZeroCostDL4Mic
    description: The 3D U-Net was first introduced by Çiçek et al for learning dense volumetric segmentations from sparsely annotated ground-truth data building upon the original U-Net architecture by Ronneberger et al. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Daniel Krentzel and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, U-Net, segmentation, ZeroCostDL4Mic, 3D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview

  - id: Notebook_StarDist_2D_ZeroCostDL4Mic
    name: StarDist (2D) - ZeroCostDL4Mic
    description: StarDist is a deep-learning method that can be used to segment cell nuclei in 2D (xy) single images or in stacks (xyz). Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/StarDist_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, StarDist, segmentation, ZeroCostDL4Mic, 2D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/StarDist_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_StarDist_2D_ZeroCostDL4Mic_2D
      - Dataset_StarDist_Fluo_ZeroCostDL4Mic
      - Dataset_StarDist_brightfield_ZeroCostDL4Mic
      - Dataset_StarDist_brightfield2_ZeroCostDL4Mic

  - id: Notebook_StarDist_3D_ZeroCostDL4Mic
    name: StarDist (3D) - ZeroCostDL4Mic
    description: StarDist is a deep-learning method that can be used to segment cell nuclei in 3D (xyz) images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/StarDist_3D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, StarDist, segmentation, ZeroCostDL4Mic, 3D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/StarDist_3D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview

  - id: Notebook_Noise2Void_2D_ZeroCostDL4Mic
    name: Noise2Void (2D) - ZeroCostDL4Mic
    description: Noise2Void 2D is deep-learning method that can be used to denoise 2D microscopy images. By running this notebook, you can train your own network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Romain Laine and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Noise2Void_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, Noise2VOID, denoising, ZeroCostDL4Mic, 2D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Noise2Void_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_Noise2Void_2D_ZeroCostDL4Mic

  - id: Notebook_Noise2Void_3D_ZeroCostDL4Mic
    name: Noise2VOID (3D) - ZeroCostDL4Mic
    description: Noise2VOID 3D is deep-learning method that can be used to denoise 3D microscopy images. By running this notebook, you can train your own network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Romain Laine and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Noise2Void_3D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, Noise2Void, denoising, ZeroCostDL4Mic, 3D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Noise2Void_3D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_Noise2Void_3D_ZeroCostDL4Mic

  - id: Notebook_CARE_2D_ZeroCostDL4Mic
    name: CARE (2D) - ZeroCostDL4Mic
    description: CARE is a neural network capable of image restoration from corrupted bio-images, first published in 2018 by Weigert et al. in Nature Methods. The network allows image denoising and resolution improvement in 2D and 3D images, in a supervised training manner. The function of the network is essentially determined by the set of images provided in the training dataset. For instance, if noisy images are provided as input and high signal-to-noise ratio images are provided as targets, the network will perform denoising. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Lucas von Chamier and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CARE_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, CARE, denoising, ZeroCostDL4Mic, 2D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CARE_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_CARE_2D_ZeroCostDL4Mic

  - id: Notebook_CARE_3D_ZeroCostDL4Mic
    name: CARE (3D) - ZeroCostDL4Mic
    description: CARE is a neural network capable of image restoration from corrupted bio-images, first published in 2018 by Weigert et al. in Nature Methods. The network allows image denoising and resolution improvement in 2D and 3D images, in a supervised training manner. The function of the network is essentially determined by the set of images provided in the training dataset. For instance, if noisy images are provided as input and high signal-to-noise ratio images are provided as targets, the network will perform denoising. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Lucas von Chamier and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CARE_3D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, CARE, denoising, ZeroCostDL4Mic, 3D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CARE_3D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_CARE_3D_ZeroCostDL4Mic

  - id: Notebook_fnet_3D_ZeroCostDL4Mic
    name: Label-free Prediction - fnet - (3D) ZeroCostDL4Mic
    description: Label-free Prediction (fnet) is a neural network used to infer the features of cellular structures from brightfield or EM images without coloured labels. The network is trained using paired training images from the same field of view, imaged in a label-free (e.g. brightfield) and labelled condition (e.g. fluorescent protein). When trained, this allows the user to identify certain structures from brightfield images alone. The performance of fnet may depend significantly on the structure at hand. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Lucas von Chamier and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/fnet_3D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, fnet, labelling, ZeroCostDL4Mic, 3D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/fnet_3D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_fnet_3D_ZeroCostDL4Mic

  - id: Notebook_fnet_2D_ZeroCostDL4Mic
    name: Label-free Prediction - fnet - (2D) ZeroCostDL4Mic
    description: Label-free Prediction (fnet) is a neural network used to infer the features of cellular structures from brightfield or EM images without coloured labels. The network is trained using paired training images from the same field of view, imaged in a label-free (e.g. brightfield) and labelled condition (e.g. fluorescent protein). When trained, this allows the user to identify certain structures from brightfield images alone. The performance of fnet may depend significantly on the structure at hand. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Lucas von Chamier and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/fnet_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, fnet, labelling, ZeroCostDL4Mic, 2D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/fnet_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview


  - id: Notebook_Deep-STORM_2D_ZeroCostDL4Mic
    name: Deep-STORM (2D) - ZeroCostDL4Mic
    description: Deep-STORM is a neural network capable of image reconstruction from high-density single-molecule localization microscopy (SMLM), first published in 2018 by Nehme et al. in Optica. This network allows image reconstruction of 2D super-resolution images, in a supervised training manner. The network is trained using simulated high-density SMLM data for which the ground-truth is available. These simulations are obtained from random distribution of single molecules in a field-of-view and therefore do not imprint structural priors during training. The network output a super-resolution image with increased pixel density (typically upsampling factor of 8 in each dimension). Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Romain Laine and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Deep-STORM_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, Deep-STORM, labelling, ZeroCostDL4Mic, 2D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Deep-STORM_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_Deep-STORM_ZeroCostDL4Mic

  - id: Notebook_pix2pix_2D_ZeroCostDL4Mic
    name: pix2pix (2D) - ZeroCostDL4Mic
    description: pix2pix is a deep-learning method that can be used to translate one type of images into another. While pix2pix can potentially be used for any type of image-to-image translation, we demonstrate that it can be used to predict a fluorescent image from another fluorescent image. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/pix2pix_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, pix2pix, ZeroCostDL4Mic, 2D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/pix2pix_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_pix2pix_ZeroCostDL4Mic

  - id: Notebook_CycleGAN_2D_ZeroCostDL4Mic
    name: CycleGAN (2D) - ZeroCostDL4Mic
    description: CycleGAN is a method that can capture the characteristics of one image domain and figure out how these characteristics could be translated into another image domain, all in the absence of any paired training examples (ie transform a horse into zebra or apples into oranges). While CycleGAN can potentially be used for any type of image-to-image translation, we illustrate that it can be used to predict what a fluorescent label would look like when imaged using another imaging modalities. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/CycleGAN_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, CycleGAN, ZeroCostDL4Mic, 2D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/CycleGAN_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_CycleGAN_ZeroCostDL4Mic

  - id: Notebook_Augmentor_ZeroCostDL4Mic
    name: Augmentor - ZeroCostDL4Mic
    description: Augmentor is a data augmentation library. Data augmentation can improve training progress by amplifying differences in the dataset. This can be useful if the available dataset is small since, in this case, it is possible that a network could quickly learn every example in the dataset (overfitting), without augmentation. Augmentation can be especially valuable when training dataset need to be manually labelled. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Tools/Augmentor_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, Augmentor, Data Augmentation, ZeroCostDL4Mic]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Tools/Augmentor_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview

  - id: Notebook_DenoiSeg_2D_ZeroCostDL4Mic
    name: DenoiSeg (2D) - ZeroCostDL4Mic
    description: DenoiSeg 2D is deep-learning method that can be used to jointly denoise and segment 2D microscopy images. The benefits of using DenoiSeg (compared to other Deep Learning-based segmentation methods) are more prononced when only a few annotated images are available. However, the denoising part requires many images to perform well. All the noisy images don't need to be labeled to train DenoiSeg. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DenoiSeg_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, CycleGAN, ZeroCostDL4Mic, 2D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DenoiSeg_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview

  - id: Notebook_Deep-STORM_2D_ZeroCostDL4Mic_DeepImageJ
    name: Deep-STORM (2D) - ZeroCostDL4Mic - DeepImageJ
    description: Deep-STORM is a neural network capable of image reconstruction from high-density single-molecule localization microscopy (SMLM), first published in 2018 by Nehme et al. in Optica. This network allows image reconstruction of 2D super-resolution images, in a supervised training manner. The network is trained using simulated high-density SMLM data for which the ground-truth is available. These simulations are obtained from random distribution of single molecules in a field-of-view and therefore do not imprint structural priors during training. The network output a super-resolution image with increased pixel density (typically upsampling factor of 8 in each dimension). Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these. Networks trained in this notebook can be used in Fiji via deepImageJ and ThunderSTORM plugin.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic teams
    covers:
      - https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/Deep-STORM_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, Deep-STORM, DeepImageJ, ZeroCostDL4Mic, 2D, deepImageJ]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/Deep-STORM_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_Deep-STORM_ZeroCostDL4Mic
      
  - id: Notebook_U-Net_3D_ZeroCostDL4Mic_DeepImageJ
    name: U-Net (3D) - ZeroCostDL4Mic - DeepImageJ
    description: The 3D U-Net was first introduced by Çiçek et al for learning dense volumetric segmentations from sparsely annotated ground-truth data building upon the original U-Net architecture by Ronneberger et al. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these. Networks trained in this notebook can be used in Fiji via deepImageJ.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic teams
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_3D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, U-Net, segmentation, ZeroCostDL4Mic, 3D, deepimagej]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_3D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview


  - id: Notebook_U-Net_2D_ZeroCostDL4Mic_DeepImageJ
    name: U-Net (2D) - ZeroCostDL4Mic - DeepImageJ
    description: U-Net is an encoder-decoder architecture originally used for image segmentation. The first half of the U-Net architecture is a downsampling convolutional neural network which acts as a feature extractor from input images. The other half upsamples these results and restores an image by combining results from downsampling with the upsampled images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these. Networks trained in this notebook can be used in Fiji via deepImageJ.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic teams
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, U-Net, segmentation, ZeroCostDL4Mic, 2D, deepimagej]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/U-Net_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview

      
  - id: Notebook_StarDist_2D_ZeroCostDL4Mic_DeepImageJ
    name: StarDist (2D) - ZeroCostDL4Mic - DeepImageJ
    description: StarDist is a deep-learning method that can be used to segment cell nuclei in 2D (xy) images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these. Networks trained in this notebook can be used in Fiji via deepImageJ and StarDist plugins for ImageJ.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Estibaliz Gómez de Mariscal and the deepImageJ and the ZeroCostDL4Mic teams
    covers:
      - https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/BioImage.io%20notebooks/StarDist_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, StarDist, segmentation, ZeroCostDL4Mic, 2D, deepimagej]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/BioImage.io%20notebooks/StarDist_2D_ZeroCostDL4Mic_BioImageModelZoo_export.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview      
      
  - id: Notebook_RCAN_3D_ZeroCostDL4Mic
    name: RCAN (3D) - ZeroCostDL4Mic
    description: RCAN is a neural network capable of image restoration from corrupted bio-images. The network allows image denoising and resolution improvement in 3D images, in a supervised training manner. The function of the network is essentially determined by the set of images provided in the training dataset. For instance, if noisy images are provided as input and high signal-to-noise ratio images are provided as targets, the network will perform denoising. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/3D-RCAN_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, CARE, denoising, ZeroCostDL4Mic, 3D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/3D-RCAN_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_CARE_3D_ZeroCostDL4Mic

  - id: Notebook_SplineDist_2D_ZeroCostDL4Mic
    name: SplineDist (2D) - ZeroCostDL4Mic
    description: SplineDist is a neural network inspired by StarDist, capable of performing image instance segmentation. Unlike StarDist, SplineDist uses cubic splines to describe the contour of each object and therefore can potentially segment objects of any shapes. This version is only for 2D dataset. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Romain F. Laine and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Wiki_files/SplineDist_overlay_cropped.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/SplineDist_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, SplineDist, segmentation, ZeroCostDL4Mic]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/SplineDist_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_StarDist_2D_ZeroCostDL4Mic_2D
      - Dataset_StarDist_Fluo_ZeroCostDL4Mic
      - Dataset_StarDist_brightfield_ZeroCostDL4Mic
      - Dataset_StarDist_brightfield2_ZeroCostDL4Mic

  - id: Notebook_YOLOv2_ZeroCostDL4Mic
    name: YOLOv2 - ZeroCostDL4Mic
    description: YOLOv2 is an object detection network developed by Redmon & Farhadi, which identifies objects in images and draws bounding boxes around them. 
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Lucas von Chamier and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/YOLOv2_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, YOLOv2, object detection, ZeroCostDL4Mic]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/YOLOv2_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_YOLOv2_ZeroCostDL4Mic      

  - id: Notebook_Detectron2_ZeroCostDL4Mic
    name: Detectron2 - ZeroCostDL4Mic
    description: Detectron2 is an object detection network developed by Facebook AI Research, which identifies objects in images and draws bounding boxes around them. 
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/Detectron2_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, Detectron2, object detection, ZeroCostDL4Mic]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/Detectron2_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_YOLOv2_ZeroCostDL4Mic

  - id: Notebook_DRMIME_ZeroCostDL4Mic
    name: DRMIME - ZeroCostDL4Mic
    description: DRMIME is an network that can be used to register microscopy images (affine and perspective registration). 
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DRMIME_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, DRMIME, image registration, ZeroCostDL4Mic]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DRMIME_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      
  - id: Notebook_Cellpose_2D_ZeroCostDL4Mic
    name: Cellpose (2D) - ZeroCostDL4Mic
    description: Cellpose is a generalist algorithm for cellular segmentation. 
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/Cellpose_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, Cellpose, Segmentation, ZeroCostDL4Mic]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/Cellpose_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_StarDist_2D_ZeroCostDL4Mic_2D
      - Dataset_StarDist_Fluo_ZeroCostDL4Mic
      - Dataset_StarDist_brightfield_ZeroCostDL4Mic
      - Dataset_StarDist_brightfield2_ZeroCostDL4Mic
  
  - id: Notebook_RetinaNet_ZeroCostDL4Mic
    name: RetinaNet - ZeroCostDL4Mic
    description: RetinaNet is a is an object detection network, which identifies objects in images and draws bounding boxes around them. 
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Erlantz Calvo, Ignacio Arganda-Carreras and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/RetinaNet_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, RetinaNet, object detection, ZeroCostDL4Mic]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/RetinaNet_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_YOLOv2_ZeroCostDL4Mic

  - id: Notebook_DecoNoising_2D_ZeroCostDL4Mic
    name: DecoNoising (2D) - ZeroCostDL4Mic
    description: DecoNoising 2D is deep-learning method that can be used to denoise 2D microscopy images. By running this notebook, you can train your own network and denoise your images. Note - visit the ZeroCostDL4Mic wiki to check the original publications this network is based on and make sure you cite these.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/DecoNoising_2D_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, DecoNoising, denoising, ZeroCostDL4Mic, 2D]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/DecoNoising_2D_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      - Dataset_Noise2Void_2D_ZeroCostDL4Mic


  - id: Notebook_Interactive_Segmentation_Kaibu_2D_ZeroCostDL4Mic
    name: Interactive Segmentation - Kaibu (2D) - ZeroCostDL4Mic
    description: Interactive Segmentation using Kaibu and Cellpose. 
    cite:
      text: "Ouyang W, Le T, Xu H and Lundberg E. Interactive biomedical segmentation tool powered by deep learning and ImJoy [version 1; peer review: 1 approved, 1 approved with reservations]. F1000Research 2021, 10:142 (https://doi.org/10.12688/f1000research.50798.1)"
      doi: https://doi.org/10.12688/f1000research.50798.1
    authors:
      - Romain Laine, Wei Ouyang and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/ZeroCostDL4Mic_Interactive_annotations_Cellpose.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, Cellpose, Segmentation, ZeroCostDL4Mic]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/ZeroCostDL4Mic_Interactive_annotations_Cellpose.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      
  - id: Notebook_MaskRCNN_ZeroCostDL4Mic
    name: MaskRCNN - ZeroCostDL4Mic
    description: MaskRCNN is a is an object detection and segmentation network, which identifies objects in images and draws bounding boxes around them. 
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Lucas von Chamier and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/Beta%20notebooks/MaskRCNN_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, MaskRCNN, object detection, ZeroCostDL4Mic]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Beta%20notebooks/MaskRCNN_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      
  - id: Notebook_Quality_Control_ZeroCostDL4Mic
    name: Quality Control - ZeroCostDL4Mic
    description: This notebooks enable to perform error mapping and quality metrics estimation.
    cite:
      text: "von Chamier, L., Laine, R.F., Jukkala, J. et al. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nat Commun 12, 2276 (2021). https://doi.org/10.1038/s41467-021-22518-0"
      doi: https://doi.org/10.1038/s41467-021-22518-0
    authors:
      - Guillaume Jacquemet and the ZeroCostDL4Mic Team
    covers:
      - https://raw.githubusercontent.com/oeway/ZeroCostDL4Mic/master/Wiki_files/ZeroCostDL4Mic_SuppVideo2_Analysis_of_example_data.png
    badges:
      - label: Open in Colab
        icon: https://colab.research.google.com/assets/colab-badge.svg
        url: https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Tools/Quality_Control_ZeroCostDL4Mic.ipynb
    documentation: https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki
    tags: [colab, notebook, Quality Control, ZeroCostDL4Mic]
    source: https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Tools/Quality_Control_ZeroCostDL4Mic.ipynb
    git_repo: https://github.com/HenriquesLab/ZeroCostDL4Mic
    links:
      - Notebook Preview
      
